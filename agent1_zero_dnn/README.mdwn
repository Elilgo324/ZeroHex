# HexNet

This is a computer [hex](https://www.hexwiki.net/) player based on deep
convolutional neural networks, which I've written mostly as an exercise to
teach myself about machine learning and tensorflow. The network architecture
and search algorithm is basically copied from [AlphaGo
Zero](https://deepmind.com/blog/alphago-zero-learning-scratch/), but adapted to
hex.

Unlike AlphaGo, selfplay games are generated using only the policy network; a
game is generated by sampling from the distribution output by the policy
network each move, then one position is taken from each game and MCTS is
applied to that position to obtain a training example (using the output of MCTS
as a target for the policy output and the game result as a target for the value
output). This gives a larger number of independent training examples for less
computational cost (though lower quality).

This can be played against with [HexGui](https://github.com/apetresc/hexgui),
setting gtp.py as the program. It uses python 3 and requires numpy, keras and
tensorflow.